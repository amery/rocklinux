--- linux-2.6.9-rock/include/linux/types.h	2004-12-08 18:08:42.000000000 +0100
+++ usr/include/linux/types.h	2004-12-25 07:15:44.000000000 +0100
@@ -131,6 +131,12 @@
 #ifndef HAVE_SECTOR_T
 typedef unsigned long sector_t;
 #endif
+#endif /* __KERNEL_STRICT_NAMES */
+
+/*
+ * Below are truly Linux-specific types that should never collide with
+ * any application/library that wants linux/types.h.
+ */
 
 /*
  * The type of an index into the pagecache.  Use a #define so asm/types.h
@@ -150,15 +156,11 @@
 typedef __u16 __bitwise __be16;
 typedef __u32 __bitwise __le32;
 typedef __u32 __bitwise __be32;
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
 typedef __u64 __bitwise __le64;
 typedef __u64 __bitwise __be64;
+#endif
 
-#endif /* __KERNEL_STRICT_NAMES */
-
-/*
- * Below are truly Linux-specific types that should never collide with
- * any application/library that wants linux/types.h.
- */
 
 struct ustat {
 	__kernel_daddr_t	f_tfree;
diff -dur /usr/include/linux/byteorder/big_endian.h build/k6-desktop-2.1.0-DEV-x86-k6-32-desktop-expert/usr/include/linux/byteorder/big_endian.h
--- usr/include/linux/byteorder/big_endian.h	2004-12-08 02:12:31.000000000 +0100
+++ build/k6-desktop-2.1.0-DEV-x86-k6-32-desktop-expert/usr/include/linux/byteorder/big_endian.h	2004-12-25 08:03:08.694401672 +0100
@@ -30,31 +15,57 @@
 #define __constant_ntohl(x) ((__force __u32)(__be32)(x))
 #define __constant_htons(x) ((__force __be16)(__u16)(x))
 #define __constant_ntohs(x) ((__force __u16)(__be16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __constant_cpu_to_le64(x) ((__force __le64)___constant_swab64((x)))
 #define __constant_le64_to_cpu(x) ___constant_swab64((__force __u64)(__le64)(x))
+
+#endif
+
 #define __constant_cpu_to_le32(x) ((__force __le32)___constant_swab32((x)))
 #define __constant_le32_to_cpu(x) ___constant_swab32((__force __u32)(__le32)(x))
 #define __constant_cpu_to_le16(x) ((__force __le16)___constant_swab16((x)))
 #define __constant_le16_to_cpu(x) ___constant_swab16((__force __u16)(__le16)(x))
 #define __constant_cpu_to_be64(x) ((__force __be64)(__u64)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __constant_be64_to_cpu(x) ((__force __u64)(__be64)(x))
+
+#endif
+
 #define __constant_cpu_to_be32(x) ((__force __be32)(__u32)(x))
 #define __constant_be32_to_cpu(x) ((__force __u32)(__be32)(x))
 #define __constant_cpu_to_be16(x) ((__force __be16)(__u16)(x))
 #define __constant_be16_to_cpu(x) ((__force __u16)(__be16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __cpu_to_le64(x) ((__force __le64)___swab64((x)))
 #define __le64_to_cpu(x) ___swab64((__force __u64)(__le64)(x))
+
+#endif
+
 #define __cpu_to_le32(x) ((__force __le32)___swab32((x)))
 #define __le32_to_cpu(x) ___swab32((__force __u32)(__le32)(x))
 #define __cpu_to_le16(x) ((__force __le16)___swab16((x)))
 #define __le16_to_cpu(x) ___swab16((__force __u16)(__le16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __cpu_to_be64(x) ((__force __be64)(__u64)(x))
 #define __be64_to_cpu(x) ((__force __u64)(__be64)(x))
+
+#endif
+
 #define __cpu_to_be32(x) ((__force __be32)(__u32)(x))
 #define __be32_to_cpu(x) ((__force __u32)(__be32)(x))
 #define __cpu_to_be16(x) ((__force __be16)(__u16)(x))
 #define __be16_to_cpu(x) ((__force __u16)(__be16)(x))
 
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 static inline __le64 __cpu_to_le64p(const __u64 *p)
 {
 	return (__force __le64)__swab64p(p);
@@ -63,6 +74,9 @@
 {
 	return __swab64p((__u64 *)p);
 }
+
+#endif
+
 static inline __le32 __cpu_to_le32p(const __u32 *p)
 {
 	return (__force __le32)__swab32p(p);
@@ -79,6 +93,9 @@
 {
 	return __swab16p((__u16 *)p);
 }
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 static inline __be64 __cpu_to_be64p(const __u64 *p)
 {
 	return (__force __be64)*p;
@@ -87,6 +104,9 @@
 {
 	return (__force __u64)*p;
 }
+
+#endif
+
 static inline __be32 __cpu_to_be32p(const __u32 *p)
 {
 	return (__force __be32)*p;
@@ -103,14 +123,26 @@
 {
 	return (__force __u16)*p;
 }
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __cpu_to_le64s(x) __swab64s((x))
 #define __le64_to_cpus(x) __swab64s((x))
+
+#endif
+
 #define __cpu_to_le32s(x) __swab32s((x))
 #define __le32_to_cpus(x) __swab32s((x))
 #define __cpu_to_le16s(x) __swab16s((x))
 #define __le16_to_cpus(x) __swab16s((x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __cpu_to_be64s(x) do {} while (0)
 #define __be64_to_cpus(x) do {} while (0)
+
+#endif
+
 #define __cpu_to_be32s(x) do {} while (0)
 #define __be32_to_cpus(x) do {} while (0)
 #define __cpu_to_be16s(x) do {} while (0)
diff -dur /usr/include/linux/byteorder/little_endian.h build/k6-desktop-2.1.0-DEV-x86-k6-32-desktop-expert/usr/include/linux/byteorder/little_endian.h
--- usr/include/linux/byteorder/little_endian.h	2004-12-08 02:12:31.000000000 +0100
+++ build/k6-desktop-2.1.0-DEV-x86-k6-32-desktop-expert/usr/include/linux/byteorder/little_endian.h	2004-12-25 08:05:34.293267280 +0100
@@ -30,31 +15,57 @@
 #define __constant_ntohl(x) ___constant_swab32((__force __be32)(x))
 #define __constant_htons(x) ((__force __be16)___constant_swab16((x)))
 #define __constant_ntohs(x) ___constant_swab16((__force __be16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __constant_cpu_to_le64(x) ((__force __le64)(__u64)(x))
 #define __constant_le64_to_cpu(x) ((__force __u64)(__le64)(x))
+
+#endif
+
 #define __constant_cpu_to_le32(x) ((__force __le32)(__u32)(x))
 #define __constant_le32_to_cpu(x) ((__force __u32)(__le32)(x))
 #define __constant_cpu_to_le16(x) ((__force __le16)(__u16)(x))
 #define __constant_le16_to_cpu(x) ((__force __u16)(__le16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __constant_cpu_to_be64(x) ((__force __be64)___constant_swab64((x)))
 #define __constant_be64_to_cpu(x) ___constant_swab64((__force __u64)(__be64)(x))
+
+#endif
+
 #define __constant_cpu_to_be32(x) ((__force __be32)___constant_swab32((x)))
 #define __constant_be32_to_cpu(x) ___constant_swab32((__force __u32)(__be32)(x))
 #define __constant_cpu_to_be16(x) ((__force __be16)___constant_swab16((x)))
 #define __constant_be16_to_cpu(x) ___constant_swab16((__force __u16)(__be16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __cpu_to_le64(x) ((__force __le64)(__u64)(x))
 #define __le64_to_cpu(x) ((__force __u64)(__le64)(x))
+
+#endif
+
 #define __cpu_to_le32(x) ((__force __le32)(__u32)(x))
 #define __le32_to_cpu(x) ((__force __u32)(__le32)(x))
 #define __cpu_to_le16(x) ((__force __le16)(__u16)(x))
 #define __le16_to_cpu(x) ((__force __u16)(__le16)(x))
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 #define __cpu_to_be64(x) ((__force __be64)___swab64((x)))
 #define __be64_to_cpu(x) ___swab64((__force __u64)(__be64)(x))
+
+#endif
+
 #define __cpu_to_be32(x) ((__force __be32)___swab32((x)))
 #define __be32_to_cpu(x) ___swab32((__force __u32)(__be32)(x))
 #define __cpu_to_be16(x) ((__force __be16)___swab16((x)))
 #define __be16_to_cpu(x) ___swab16((__force __u16)(__be16)(x))
 
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 static inline __le64 __cpu_to_le64p(const __u64 *p)
 {
 	return (__force __le64)*p;
@@ -63,6 +74,9 @@
 {
 	return (__force __u64)*p;
 }
+
+#endif
+
 static inline __le32 __cpu_to_le32p(const __u32 *p)
 {
 	return (__force __le32)*p;
@@ -79,6 +93,9 @@
 {
 	return (__force __u16)*p;
 }
+
+#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
+
 static inline __be64 __cpu_to_be64p(const __u64 *p)
 {
 	return (__force __be64)__swab64p(p);
@@ -87,6 +104,9 @@
 {
 	return __swab64p((__u64 *)p);
 }
+
+#endif
+
 static inline __be32 __cpu_to_be32p(const __u32 *p)
 {
 	return (__force __be32)__swab32p(p);
